% ABSTRACT:

%Many important parts of modern scientific research depend on writing, sharing, and running reproducible code. It enables scientists to collaborate on projects, replicate and extend prior work, and teach students new ideas and techniques through hands-on, interactive tutorials.

%The ability to write, share, and run reproducible code plays many important roles in modern scientific research:

%Writing and sharing reproducible code plays an important role in modern scientific research, enabling scientists to collaborate on projects, replicate and extend previous work, and teach students concepts and techniques through

%\texttt{davos} is a Python package that provides a simple, accessible, and effective way to manage and share reproducible code.

%\texttt{davos} provides the \texttt{smuggle} statement

%\texttt{davos} is a Python package that allows users to write, run, and share reproducible Python code without the need for containers or virtual environments.

%davos is a Python package that allows users to manage and share reproducible code without the need for containers or virtual environments.

%\texttt{davos} is a Python package for creating, running, and sharing reproducible workflows without the need for external containerized or virtualized environments.

%\texttt{davos} is a Python package that makes writing, running, and sharing reproducible code easy. Importing \texttt{davos} in an IPython notebook enables the \textit{smuggle} statement: a drop-in replacement for the built-in \textit{import} statement that can install missing packages as needed at runtime, and may be

%\texttt{davos} is a Python package for creating self-managing, reproducible workflows that specify dependencies directly within their code and install packages as needed at runtime.

%\texttt{davos} works by providing the \textit{smuggle} statement: a drop-in replacement for the built-in \texttt{import} statement that  \_\_\_, and the

% \texttt{davos} is a Python package for creating self-managing, reproducible workflows that specify dependencies directly in their code, and install them
% \texttt{davos} is a Python package that enables creating and sharing reproducible workflows as a single, ready-to-run IPython notebook.

%davos is a python package for creating, sharing, and running reproducible code without the need for


% ========================================================================================================


% Modern open science practices promote sharing code and data to enable others to explore, reproduce, learn from, and build upon existing work. Scientists, researchers, and educators produce many different forms of research-related code (e.g., experiments, data analyses, tutorials, demos) that they may seek to share with a wide range of audiences including collaborators, students, the broader scientific community, and the general public. Python has become one of the most widely used and fastest-growing scientific programming languages as it offers both a simple, accessible grammar and an extensive 

%Modern scientific research frequently involves writing code for different purposes throughout the research process (e.g., experiments, data analyses, tutorials, or demos). A nearly universal (but often challenging) requirement of research-related code is that its behavior and outputs must remain consistent every time it is run, both over time and across users. This stability can be crucial to ensuring that data are collected under identical conditions (e.g., across recordings, trials, or subjects) and that statistical analyses yield accurate, consistent results. Additionally, modern open science practices encourage sharing code and data publicly to enable others to explore, reproduce, learn from, and build upon existing work. Scientists, researchers, and educators may seek to share research-related code with a wide range of audiences including collaborators, students, the broader scientific community, and the general public.

%Modern scientific research often involves writing code that must behave consistently every time it is run. For example, stable code can be crucial to ensuring data are collected under the same conditions, recorded and processed in a common format, and yield reliable results when analyzed. Additionally, modern open science practices promote sharing code and data to enable others to explore, reproduce, learn from, and build upon existing work. Scientists, researchers, and educators produce many different forms of research-related code (e.g., experiments, data analyses, tutorials, demos) that they may seek to share with a wide range of audiences including collaborators, students, the broader scientific community, and the general public. 

%%Modern scientific research frequently involves writing code for different purposes throughout the research process (e.g., experiments, data analyses, tutorials, or demos). An often essential (but often challenging) part of writing code for scientific research is ensuring its behavior and outputs remain consistent every time it is run, both over time and across users.

% Modern scientific research often involves writing code for various uses throughout the research process (e.g., experiments, data analyses, tutorials, and demos). An often-essential feature of research-related code is that it must behave consistently 

% A common challenge when writing 

%A common requirement of code written for scientific research is that it must behave consistently every time it is run. This 

% Modern scientific research frequently involves writing code whose behavior and outputs must be consistent every time it is run. This stability is essential for 

%When writing code for scientific research, it is often essential to ensure that the code 

%Modern scientific research frequently involves writing code whose behavior must be consistent every time it is run. This stability is essential to ensuring 

%An essential part of modern scientific research is writing code that behaves consistently every time it is run. Stable code is crucial to ensuring data are collected under the same conditions across trials, subjects, or observations; recorded and processed in a standard format; 

%For example, stable code helps ensure data are collected, recorded, and processed consistently, and that analyses performed on those data yield reliable results. 

%Code that remains stable over time is essential to ensuring that data are collected under constant conditions, recorded and stored in a standard format, and yield accurate results when analyzed.

%For example, stable code helps ensure all data are collected under consistent conditions, recorded and stored in a consistent format, and treated consistently during analyses.
 
% An essential feature of software used in scientific research is that it behaves consistently every time it is run. For example, stable code can be crucial to ensuring constant conditions during data collection (e.g., across recordings, trials, or subjects) and that accurate, reliable outputs from statistical analyses. Additionally, modern open science practices encourage sharing code and data to enable others to explore, reproduce, learn from, and build upon existing work. Scientists, researchers, and educators produce many different forms of research-related code (e.g., experiments, analyses, tutorials, and demos) that they may seek to share with a wide range of audiences including collaborators, students, the broader scientific community, and the general public.

%Modern scientific research often involves writing code for various purposes throughout the research process, from designing experiments to performing data analyses to presenting results through tutorials or demos. A nearly universal requirement of any form of research-related code is that its behavior and outputs must remain consistent every time it is run, both over time and across users. This stability can be crucial to ensuring that data are collected under identical conditions (e.g., across recordings, trials, or subjects) and that statistical analyses yield accurate, consistent results. Additionally, open science practices encourage sharing code and data publicly to enable others to explore, reproduce, learn from, and build upon existing work. Scientists, researchers, and educators may seek to share research-related code with a wide range of audiences including collaborators, students, the broader scientific community, and the general public.

%Modern scientific research often involves writing code throughout the research process, from designing experiments, to analyzing data, to presenting findings via tutorials or public demos. 

%Modern scientific research frequently entails writing software code for a wide range of purposes throughout the research process, from designing experiments, to processing and analyzing data, to sharing results and techniques with peers or students through tutorials, demos, workshops, and classes. One requirement common to nearly all research-related code it that its behavior and/or outputs remain consistent and predictable every time it is run, both over time and across different users. For instance, this stability can be crucial to ensuring that data are collected under the same conditions (e.g., across recordings, trials, or subjects) and that statistical analyses yield accurate, reliable results. 

%However, one requirement common to virtually all forms of research-related code is that it behave consistently and predictably every time it is run, both over time and across users.
%This stability can be crucial, for example, to carrying out studies that span multiple years or institutions
%This stability can be crucial to ensuring, for example, that data are collected under the same conditions (e.g., across recordings, trials, or subjects) over multiple months or years, and can be accessed, processed, and analyzed consistently by collaborators across multiple institutions or countries.

%For example, this stability can be crucial to ensuring that data are collected under the same conditions (e.g., across recordings, trials, or subjects), preprocessed in the same manner, stored in a standardized format, and treated equitably by statistical analyses.
%This stability can be crucial to ensuring, for example, that data are collected under constant conditions (e.g., across recordings, trials, or subjects), are preprocessed and stored in a standard format, and that they can be easily accessed and consistently analyzed by collaborators across multiple institutions or countries.

%Scientists, researchers, and educators may seek to share research code with audiences that have a broad range of scientific and technical backgrounds, including collaborators, students, 
%stakeholders, 
%the broader scientific community, and the general public.


% ========================================================================================================


%Python has become one of the most widely used and fastest-growing scientific programming languages \cite{MullEtal15}, in part due to its accessible, high-level grammar and extensive ecosystem of powerful third-party data science tools, including platforms for interactive development (e.g., Project Jupyter, \cite{KluyEtal16}; Google Colaboratory), community-maintained libraries for data manipulation (e.g., \texttt{NumPy} \cite{HarrEtal20}, \texttt{SciPy} \cite{VirtEtal20}, \texttt{Pandas} \cite{McKi10}) and visualization (e.g., \texttt{Matplotlib} \cite{Hunt07}, \texttt{seaborn} \cite{Wask21}), and myriad other software. However, this heavy use of third-party packages also presents a challenge to writing and sharing stable, reproducible scientific Python code: different versions of the same third-party library can behave differently, use different syntax, add or drop support for specific functions or other libraries, address (or introduce) bugs, and so on. While these issues are present to some extent in any language or ecosystem, they have a particular impact on the Python community due to its unusually rapid growth relative to other languages. Ensuring consistent behavior over time and across users therefore typically requires ensuring that code is shared and run with a specific set of versions for each package used. 

%the availability of powerful third-party tools \cite{MullEtal15} . 
%an extensive ecosystem of third-party tools \cite{MullEtal15}.

%Python \cite{vanR95} has become one of the most widely used and fastest-growing scientific programming languages by combining an accessible, high-level syntax with the availability of powerful third-party tools that facilitate rapid development and collaboration \cite{MullEtal15}.


%However, this heavy emphasis on third-party libraries also presents a challenge to writing and sharing stable, reproducible scientific Python code: different versions of the same library may behave differently, adopt changes in syntax, add or drop support for specific functions or other libraries, save data in (and expect loaded data to adhere to) different formats, address (or introduce) bugs, and so on.

%Ensuring Python code behaves consistently over time and across users therefore typically requires making sure it is always run with the same specific set of versions for each package used.


% ========================================================================================================


%They can also distribute this custom environment alongside their code as a configuration file that explicitly lists required package versions, enabling others to build identical copies for themselves.

% ========================================================================================================

%For example, sharing an analysis or tutorial that relies on a particular Docker image to run properly not only necessitates writing and distributing extra configuration files and setup instructions, but more significantly, requires anyone hoping to run code (including the original author) to first be able to install and navigate additional software that is likely far more complex and resource-intensive than the actual analysis or tutorial code it facilitates running.

%For example, sharing an analysis or tutorial that relies on a particular Docker image to run properly not only necessitates distributing extra configuration files and setup instructions, but also requires both the original author and anyone with whom the code is shared to first install and navigate additional software that is likely more complex and resource-intensive than the actual code it facilitates running.

%For example, sharing an analysis or tutorial that relies on a particular Docker image to run properly necessarily requires writing and distributing extra configuration files and setup instructions. But more significantly, it also requires that anyone seeking to run the code first be able to install and navigate additional software that is likely far more complex and resource-intensive than the actual analysis or tutorial it facilitates running.

%For example, sharing an analysis or tutorial that relies on a particular Docker image to run properly would, of course, necessitate writing and distributing extra configuration files (e.g., a \texttt{Dockerfile} or \texttt{docker-compose.yaml}) as well as initial setup instructions. %While this may be a mere minor inconvenience (if not a fact of everyday life) for users seasoned in DevOps tooling, the impact is far more significant in a research context, requiring both the original author and anyone else who may want to run their code (whether Z

% ========================================================================================================


% First, most tools for building a Python environment from a configuration file (e.g., ..) work by installing all requirements upfront, but typically do not enforce their presence after this initial setup. This makes it easy to inadvertently alter the environment after this initial setup. For example, suppose a researcher has implemented a series of analyses using version 1.0 of ``Package \textit{X}," and decides to perform an additional analysis that requires ``Package \textit{Y}." If Package \textit{Y} depends on version 1.1 of Package \textit{X}, then Package \textit{X} will be upgraded to accommodate this new requirement, potentially leading to inconsistent behavior of code that uses Package \textit{X}.

%Second, it can add substantially to the technical knowledge, system resources, and initial setup required to share and run the actual code of interest. For example, sharing research code that relies on a particular Docker image to run properly not only necessitates additional configuration files and setup steps, but also requires both the author and all users with whom it may be shared to install and navigate additional software that is likely more complicated and resource-intensive than the actual code being shared.

% While effective, such tools can add a significant degree of complexity to the process of sharing research code for both the author and 


% ========================================================================================================


%Second, typical environment management tools don't enforce that specified requirements \textit{remain} satisfied after they are initially installed. 

%This makes it easy to inadvertently alter existing packages in a Python environment at any point in time, potentially affecting the behavior of code that depends on them. 

%For instance, suppose a researcher has implemented a series of analyses using version 1.0 of ``Package \textit{X}," and decides to  perform an additional analysis that requires installing ``Package \textit{Y}." 

%If Package \textit{Y} depends on version 1.1 of Package \textit{X}, then Package \textit{X} will be upgrade to accommodate this new requirement, potentially altering or breaking the previous analyses in future runs, as well as for anyone with whom  analysis code. 

%Further, if earlier analyses require functionality 

%install a fixed set of required Python packages in an isolated environment (e.g., from a \texttt{requirements.txt}, \texttt{pyproject.toml}, \texttt{environment.yml}, \texttt{Pipfile}, \texttt{Dockerfile RUN} instruction, etc.), few, if any, enforce that the specified requirements \textit{remain} satisfied after this initial setup.


% ========================================================================================================


%\texttt{davos} was created\comment{designed?} to address these issues by providing a novel, Python-native framework for creating, sharing, and running reproducible workflows. The general scheme for using \textit{davos} (described in \hyperref[sec:functionalities]{\textit{Software functionalities}}, below) was designed with \textbf{NUMBER} goals in mind: to be more accessible, intuitive, and lightweight than typical environment management tools; to guarantee the desired version

%We created the davos package \comment{the davos package was created} to address these issues by providing a novel, Python-based \comment{Python-native(?)} framework for writing, sharing, and running reproducible code. davos was designed with the goal of stimultaneously being being more accessible, intuitive, and lightweight than typical environment management tools; guaranteeing that Python workflows always use the intended package versions (even beyond their initial installation); providing greater, more precise control over which package versions are used for what purposes

%We created \texttt{davos} to address these issues, with the goal of providing an alternative approach to ensuring reproducibility over time and across users that is more intuitive

%The \texttt{davos} package was designed to address these issues by providing an intuitive, lightweight, and Python-native way to ensure reproducibility over time and across users. With \texttt{davos} users to distribute reproducible workflows as a single, ready-to-run Jupyter notebook \cite{KluyEtal16} that specifies


